import asyncio
import aiohttp
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
import feedparser
import requests
from bs4 import BeautifulSoup
import re

from .base_tool import BaseTool
from ..utils.logger import get_logger
from ..utils.config import Config

logger = get_logger(__name__)

class NewsSearchTool(BaseTool):
    """
    Ferramenta para busca e an√°lise de not√≠cias relacionadas a SRAG.
    """
    
    def __init__(self):
        """Inicializa ferramenta de busca de not√≠cias."""
        super().__init__("NewsSearchTool")
        
        self.config = Config()
        self.news_api_key = self.config.get('NEWS_API_KEY')
        
        # URLs de RSS feeds confi√°veis
        self.rss_feeds = [
            'https://g1.globo.com/rss/g1/ciencia-e-saude/',
            'https://www1.folha.uol.com.br/rss/cotidiano.xml',
            'https://saude.estadao.com.br/rss.xml',
            'https://agencia.fiocruz.br/rss.xml'
        ]
        
        # Termos de busca relacionados a SRAG - EXPANDIDOS
        self.search_terms = [
            'SRAG', 'S√≠ndrome Respirat√≥ria Aguda Grave',
            's√≠ndrome respirat√≥ria', 'interna√ß√£o respirat√≥ria',
            'UTI respirat√≥rio', 'casos respirat√≥rios',
            'surto respirat√≥rio', 'epidemia respirat√≥ria',
            'gripe', 'influenza', 'covid', 'pneumonia',  # Termos adicionais
            'v√≠rus respirat√≥rio', 'doen√ßa respirat√≥ria'
        ]
        
        # Cache de not√≠cias
        self.news_cache = {}
        
        logger.info("NewsSearchTool inicializada")
    
    async def search_srag_news(
        self, 
        max_articles: int = 10,
        date_range_days: int = 120,
        sources: Optional[List[str]] = None
    ) -> List[Dict[str, Any]]:
        """
        Busca not√≠cias sobre SRAG em m√∫ltiplas fontes.
        """
        execution_id = self.log_execution_start("search_srag_news", {
            'max_articles': max_articles,
            'date_range_days': date_range_days
        })
        
        start_time = datetime.now()
        articles = []
        
        try:
            logger.info(f"Iniciando busca de not√≠cias - Range: {date_range_days} dias")
            
            # Buscar em RSS feeds
            rss_articles = await self._search_rss_feeds(date_range_days)
            logger.info(f"RSS feeds retornaram {len(rss_articles)} artigos")
            articles.extend(rss_articles)
            
            # Buscar via News API se configurada
            if self.news_api_key:
                api_articles = await self._search_news_api(date_range_days)
                logger.info(f"News API retornou {len(api_articles)} artigos")
                articles.extend(api_articles)
            else:
                logger.warning("News API key n√£o configurada")
            
            logger.info(f"Total de artigos antes de filtros: {len(articles)}")
            
            # Remover duplicatas e filtrar por relev√¢ncia
            articles = self._deduplicate_articles(articles)
            logger.info(f"Artigos ap√≥s deduplica√ß√£o: {len(articles)}")
            
            articles = self._filter_relevant_articles(articles)
            logger.info(f"Artigos ap√≥s filtro de relev√¢ncia: {len(articles)}")
            
            # Limitar quantidade
            articles = articles[:max_articles]
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            self.log_execution_end(
                execution_id, 
                True, 
                execution_time,
                f"Encontrados {len(articles)} artigos relevantes"
            )
            
            return articles
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            
            self.log_execution_end(
                execution_id, 
                False, 
                execution_time,
                error=str(e)
            )
            
            logger.error(f"Erro na busca de not√≠cias: {e}", exc_info=True)
            return []
    
    async def _search_rss_feeds(self, date_range_days: int) -> List[Dict[str, Any]]:
        """
        Busca not√≠cias em feeds RSS.
        """
        articles = []
        cutoff_date = datetime.now() - timedelta(days=date_range_days)
        
        logger.info(f"Buscando em {len(self.rss_feeds)} RSS feeds")
        logger.info(f"Data de corte: {cutoff_date.isoformat()}")
        
        for rss_url in self.rss_feeds:
            try:
                logger.info(f"Processando RSS: {rss_url}")
                
                # Parse do RSS feed com timeout
                feed = await asyncio.get_event_loop().run_in_executor(
                    None, 
                    lambda: feedparser.parse(rss_url)
                )
                
                logger.info(f"Feed {rss_url} retornou {len(feed.entries)} entradas")
                
                for entry in feed.entries:
                    # Verificar data da publica√ß√£o
                    pub_date = None
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        try:
                            pub_date = datetime(*entry.published_parsed[:6])
                        except Exception as e:
                            logger.debug(f"Erro ao parsear data: {e}")
                    
                    # MUDAN√áA: Aceitar artigos sem data OU dentro do range
                    if pub_date and pub_date < cutoff_date:
                        logger.debug(f"Artigo muito antigo: {entry.get('title', '')[:50]}")
                        continue
                    
                    # Verificar relev√¢ncia do t√≠tulo
                    title = entry.get('title', '').lower()
                    summary = entry.get('summary', '').lower()
                    content = f"{title} {summary}"
                    
                    # MUDAN√áA: Log de verifica√ß√£o de termos
                    matching_terms = [term for term in self.search_terms if term.lower() in content]
                    
                    if matching_terms:
                        logger.debug(f"Artigo relevante encontrado: {entry.get('title', '')[:50]} - Termos: {matching_terms[:3]}")
                        article = {
                            'title': entry.get('title', ''),
                            'link': entry.get('link', ''),
                            'summary': entry.get('summary', ''),
                            'published': pub_date.isoformat() if pub_date else None,
                            'source': rss_url,
                            'source_type': 'rss'
                        }
                        articles.append(article)
                
                # Rate limiting
                await asyncio.sleep(1)
                
            except Exception as e:
                logger.error(f"Erro ao processar RSS {rss_url}: {e}", exc_info=True)
        
        logger.info(f"Total de artigos coletados dos RSS feeds: {len(articles)}")
        return articles
    
    async def _search_news_api(self, date_range_days: int) -> List[Dict[str, Any]]:
        """
        Busca not√≠cias usando News API.
        """
        if not self.news_api_key:
            return []
        
        articles = []
        
        try:
            from_date = (datetime.now() - timedelta(days=date_range_days)).strftime('%Y-%m-%d')
            
            logger.info(f"Buscando via News API desde {from_date}")
            
            # Buscar para cada termo
            for term in self.search_terms[:3]:
                url = 'https://newsapi.org/v2/everything'
                params = {
                    'q': term,
                    'from': from_date,
                    'language': 'pt',
                    'sortBy': 'relevancy',
                    'apiKey': self.news_api_key,
                    'pageSize': 5
                }
                
                async with aiohttp.ClientSession() as session:
                    async with session.get(url, params=params) as response:
                        if response.status == 200:
                            data = await response.json()
                            
                            for article_data in data.get('articles', []):
                                # Skip articles with missing critical fields
                                if not article_data.get('title'):
                                    logger.debug("Skipping article without title from News API")
                                    continue
                                
                                article = {
                                    'title': article_data.get('title', ''),
                                    'link': article_data.get('url', ''),
                                    'summary': article_data.get('description', ''),
                                    'published': article_data.get('publishedAt', ''),
                                    'source': article_data.get('source', {}).get('name', 'News API'),
                                    'source_type': 'news_api'
                                }
                                articles.append(article)
                        else:
                            logger.warning(f"News API retornou status {response.status}")
                
                await asyncio.sleep(1)
                
        except Exception as e:
            logger.error(f"Erro na busca via News API: {e}", exc_info=True)
        
        return articles
    
    def _deduplicate_articles(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Remove artigos duplicados baseado no t√≠tulo."""
        seen_titles = set()
        unique_articles = []
        
        for article in articles:
            title = article.get('title') or ''  # Handle None values
            if not isinstance(title, str):
                title = str(title) if title else ''
            
            title = title.strip().lower()
            if title and title not in seen_titles:
                seen_titles.add(title)
                unique_articles.append(article)
        
        return unique_articles
    
    def _filter_relevant_articles(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Filtra artigos por relev√¢ncia ao tema SRAG.
        """
        relevant_articles = []
        
        # MUDAN√áA: Palavras-chave expandidas e menos restritivas
        relevant_keywords = [
            'srag', 'respirat√≥ria', 'respiratorio', 'respirat√≥ria', 'respirat√≥rio',
            'uti', 'interna√ß√£o', 'internacao', 'hospital', 'casos', 'surto', 'epidemia',
            'pneumonia', 'covid', 'influenza', 'h1n1', 'gripe', 'v√≠rus', 'virus',
            'sa√∫de', 'saude', 'doen√ßa', 'doenca', '√≥bito', 'obito', 'morte'
        ]
        
        for article in articles:
            # Handle None values safely
            title = article.get('title') or ''
            summary = article.get('summary') or ''
            
            # Ensure they're strings
            if not isinstance(title, str):
                title = str(title) if title else ''
            if not isinstance(summary, str):
                summary = str(summary) if summary else ''
            
            text_content = f"{title.lower()} {summary.lower()}"
            
            # Calcular score de relev√¢ncia
            relevance_score = sum(
                1 for keyword in relevant_keywords 
                if keyword in text_content
            )
            
            # MUDAN√áA: Reduzir threshold de 2 para 1
            if relevance_score >= 1:
                article['relevance_score'] = relevance_score
                relevant_articles.append(article)
                logger.debug(f"Artigo relevante (score {relevance_score}): {title[:50]}")
            else:
                logger.debug(f"Artigo descartado (score {relevance_score}): {title[:50]}")
        
        # Ordenar por relev√¢ncia
        relevant_articles.sort(key=lambda x: x.get('relevance_score', 0), reverse=True)
        
        return relevant_articles
    
    def _calculate_context_score(
        self, 
        news_texts: List[str], 
        metrics: Dict[str, Any]
    ) -> float:
        """Calcula score de contexto das not√≠cias em rela√ß√£o √†s m√©tricas."""
        if not news_texts or not metrics:
            return 0.0
        
        combined_text = ' '.join(news_texts).lower()
        context_score = 0.0
        
        # Verificar men√ß√µes a elementos das m√©tricas
        metric_keywords = {
            'cases': ['casos', 'case', 'notifica√ß√µes', 'registros'],
            'mortality': ['√≥bito', 'morte', 'mortalidade', 'falecimento'],
            'icu': ['uti', 'terapia intensiva', 'interna√ß√£o'],
            'vaccination': ['vacina', 'vacina√ß√£o', 'imuniza√ß√£o']
        }
        
        for category, keywords in metric_keywords.items():
            mentions = sum(1 for keyword in keywords if keyword in combined_text)
            context_score += min(mentions * 0.5, 2.0)
        
        # Bonus por rec√™ncia das not√≠cias
        recent_bonus = len([text for text in news_texts if text]) * 0.2
        context_score += min(recent_bonus, 2.0)
        
        return min(context_score, 10.0)
    
    def _generate_news_summary(
        self, 
        articles: List[Dict[str, Any]], 
        metrics: Dict[str, Any]
    ) -> str:
        """Gera resumo contextualizado das not√≠cias."""
        if not articles:
            return "Nenhuma not√≠cia relevante encontrada no per√≠odo analisado."
        
        # Extrair temas principais com artigos espec√≠ficos
        themes = {
            'increase': {'count': 0, 'articles': []},
            'deaths': {'count': 0, 'articles': []},
            'hospitalization': {'count': 0, 'articles': []},
            'vaccination': {'count': 0, 'articles': []},
            'alert': {'count': 0, 'articles': []},
            'prevention': {'count': 0, 'articles': []}
        }
        
        for article in articles:
            title = article.get('title', '').lower()
            summary = article.get('summary', '').lower()
            content = f"{title} {summary}"
            
            article_info = {
                'title': article.get('title', ''),
                'link': article.get('link', ''),
                'source': article.get('source', ''),
                'published': article.get('published', '')
            }
            
            if any(word in content for word in ['aumento', 'alta', 'crescimento', 'dispara', 'cresce', 'sobe']):
                themes['increase']['count'] += 1
                themes['increase']['articles'].append(article_info)
            
            if any(word in content for word in ['√≥bito', 'morte', 'mortalidade', 'falecimento', 'v√≠tima']):
                themes['deaths']['count'] += 1
                themes['deaths']['articles'].append(article_info)
            
            if any(word in content for word in ['uti', 'interna√ß√£o', 'internacao', 'hospital', 'leito']):
                themes['hospitalization']['count'] += 1
                themes['hospitalization']['articles'].append(article_info)
            
            if any(word in content for word in ['vacina', 'vacina√ß√£o', 'imuniza√ß√£o', 'dose']):
                themes['vaccination']['count'] += 1
                themes['vaccination']['articles'].append(article_info)
            
            if any(word in content for word in ['alerta', 'aten√ß√£o', 'preocupa', 'risco', 'cuidado']):
                themes['alert']['count'] += 1
                themes['alert']['articles'].append(article_info)
            
            if any(word in content for word in ['preven√ß√£o', 'prevenir', 'evitar', 'prote√ß√£o', 'cuidados']):
                themes['prevention']['count'] += 1
                themes['prevention']['articles'].append(article_info)
        
        # Gerar resumo detalhado
        summary_parts = [
            f"<h3>üìä Panorama Geral</h3>",
            f"<p>Foram analisadas {len(articles)} not√≠cias relevantes sobre SRAG e doen√ßas respirat√≥rias no per√≠odo. "
        ]
        
        # An√°lise tem√°tica
        active_themes = []
        if themes['increase']['count'] > 0:
            active_themes.append(f"aumento de casos ({themes['increase']['count']})")
        if themes['deaths']['count'] > 0:
            active_themes.append(f"mortalidade ({themes['deaths']['count']})")
        if themes['hospitalization']['count'] > 0:
            active_themes.append(f"interna√ß√µes ({themes['hospitalization']['count']})")
        if themes['vaccination']['count'] > 0:
            active_themes.append(f"vacina√ß√£o ({themes['vaccination']['count']})")
        
        if active_themes:
            summary_parts.append(f"Os principais temas cobertos pela m√≠dia incluem: {', '.join(active_themes)}.</p>")
        else:
            summary_parts.append("</p>")
        
        # An√°lise detalhada por tema
        if themes['increase']['count'] > 0:
            summary_parts.append(f"<h4>üìà Aumento de Casos</h4>")
            summary_parts.append(f"<p>{themes['increase']['count']} {'not√≠cia menciona' if themes['increase']['count'] == 1 else 'not√≠cias mencionam'} aumento nos casos respirat√≥rios. ")
            
            # Relacionar com m√©tricas
            if 'case_increase_rate' in metrics:
                rate = metrics['case_increase_rate'].get('rate', 0)
                if rate > 0:
                    summary_parts.append(f"<strong>Isto est√° alinhado com os dados oficiais que mostram um crescimento de {rate:.1f}% no per√≠odo analisado.</strong> ")
            
            summary_parts.append("As reportagens destacam:")
            summary_parts.append("<ul>")
            for art in themes['increase']['articles'][:3]:  # Mostrar at√© 3
                summary_parts.append(f"<li><a href='{art['link']}' target='_blank'>{art['title']}</a></li>")
            summary_parts.append("</ul></p>")
        
        if themes['hospitalization']['count'] > 0:
            summary_parts.append(f"<h4>üè• Interna√ß√µes e Hospitaliza√ß√£o</h4>")
            summary_parts.append(f"<p>{themes['hospitalization']['count']} {'not√≠cia aborda' if themes['hospitalization']['count'] == 1 else 'not√≠cias abordam'} quest√µes relacionadas a interna√ß√µes e ocupa√ß√£o hospitalar. ")
            
            # Relacionar com m√©tricas UTI
            if 'icu_occupancy_rate' in metrics:
                icu_rate = metrics['icu_occupancy_rate'].get('rate', 0)
                if icu_rate > 0:
                    summary_parts.append(f"Os dados mostram taxa de ocupa√ß√£o de UTI em {icu_rate:.1f}%. ")
            
            summary_parts.append("Destaques:</p>")
            summary_parts.append("<ul>")
            for art in themes['hospitalization']['articles'][:3]:
                summary_parts.append(f"<li><a href='{art['link']}' target='_blank'>{art['title']}</a></li>")
            summary_parts.append("</ul>")
        
        if themes['deaths']['count'] > 0:
            summary_parts.append(f"<h4>‚ö†Ô∏è Mortalidade</h4>")
            summary_parts.append(f"<p>{themes['deaths']['count']} {'not√≠cia menciona' if themes['deaths']['count'] == 1 else 'not√≠cias mencionam'} quest√µes de mortalidade. ")
            
            if 'mortality_rate' in metrics:
                mort_rate = metrics['mortality_rate'].get('rate', 0)
                deaths = metrics['mortality_rate'].get('deaths', 0)
                if deaths > 0:
                    summary_parts.append(f"Os dados oficiais registram {deaths} √≥bitos no per√≠odo, resultando em taxa de mortalidade de {mort_rate:.2f}%. ")
                else:
                    summary_parts.append("Os dados oficiais n√£o registram √≥bitos no per√≠odo analisado. ")
            
            summary_parts.append("Reportagens relacionadas:</p>")
            summary_parts.append("<ul>")
            for art in themes['deaths']['articles'][:3]:
                summary_parts.append(f"<li><a href='{art['link']}' target='_blank'>{art['title']}</a></li>")
            summary_parts.append("</ul>")
        
        if themes['vaccination']['count'] > 0:
            summary_parts.append(f"<h4>üíâ Vacina√ß√£o</h4>")
            summary_parts.append(f"<p>{themes['vaccination']['count']} {'not√≠cia aborda' if themes['vaccination']['count'] == 1 else 'not√≠cias abordam'} campanhas de vacina√ß√£o e imuniza√ß√£o. ")
            
            if 'vaccination_rate' in metrics:
                vac_rate = metrics['vaccination_rate'].get('rate', 0)
                summary_parts.append(f"A taxa de vacina√ß√£o no per√≠odo √© de {vac_rate:.1f}%. ")
            
            summary_parts.append("Not√≠cias sobre vacina√ß√£o:</p>")
            summary_parts.append("<ul>")
            for art in themes['vaccination']['articles'][:3]:
                summary_parts.append(f"<li><a href='{art['link']}' target='_blank'>{art['title']}</a></li>")
            summary_parts.append("</ul>")
        
        if themes['alert']['count'] > 0:
            summary_parts.append(f"<h4>üîî Alertas e Recomenda√ß√µes</h4>")
            summary_parts.append(f"<p>{themes['alert']['count']} {'not√≠cia cont√©m' if themes['alert']['count'] == 1 else 'not√≠cias cont√™m'} alertas ou recomenda√ß√µes de autoridades de sa√∫de.</p>")
        
        # Considera√ß√µes finais
        summary_parts.append("<h4>üí° Considera√ß√µes</h4>")
        summary_parts.append("<p>")
        
        if themes['increase']['count'] > 0 and 'case_increase_rate' in metrics:
            rate = metrics['case_increase_rate'].get('rate', 0)
            if rate > 10:
                summary_parts.append(f"<strong>A cobertura midi√°tica reflete adequadamente o cen√°rio epidemiol√≥gico atual, com aumento significativo de {rate:.1f}% nos casos.</strong> ")
        
        if themes['prevention']['count'] > 0:
            summary_parts.append("H√° √™nfase em medidas preventivas nas reportagens. ")
        
        if themes['vaccination']['count'] > 0:
            summary_parts.append("A m√≠dia est√° dando destaque √†s campanhas de vacina√ß√£o, o que √© positivo para conscientiza√ß√£o p√∫blica. ")
        
        summary_parts.append("</p>")
        
        # Lista completa de fontes
        summary_parts.append("<h4>üì∞ Todas as Not√≠cias Analisadas</h4>")
        summary_parts.append("<ol>")
        for article in articles:
            title = article.get('title', 'Sem t√≠tulo')
            link = article.get('link', '#')
            source = article.get('source', 'Fonte desconhecida')
            published = article.get('published', '')
            
            # Formatar data se dispon√≠vel
            date_str = ''
            if published:
                try:
                    if 'T' in published:
                        date_obj = datetime.fromisoformat(published.replace('Z', '+00:00'))
                        date_str = f" - {date_obj.strftime('%d/%m/%Y')}"
                except:
                    pass
            
            summary_parts.append(f"<li><a href='{link}' target='_blank'>{title}</a><br><small>{source}{date_str}</small></li>")
        summary_parts.append("</ol>")
        
        return '\n'.join(summary_parts)
    
    async def analyze_news_context(
        self, 
        articles: List[Dict[str, Any]], 
        metrics: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Analisa contexto das not√≠cias em rela√ß√£o √†s m√©tricas."""
        execution_id = self.log_execution_start("analyze_news_context", {
            'articles_count': len(articles),
            'metrics_available': list(metrics.keys())
        })
        
        start_time = datetime.now()
        
        try:
            if not articles:
                return {
                    'summary': 'Nenhuma not√≠cia relevante encontrada para an√°lise',
                    'articles': [],
                    'context_score': 0.0
                }
            
            # Extrair textos principais
            news_texts = []
            for article in articles:
                text = f"{article.get('title', '')} {article.get('summary', '')}"
                news_texts.append(text)
            
            # Calcular score de contexto
            context_score = self._calculate_context_score(news_texts, metrics)
            
            # Gerar resumo das not√≠cias (agora em HTML com links)
            summary = self._generate_news_summary(articles, metrics)
            
            # Adicionar metadados √∫teis aos artigos
            enriched_articles = []
            for article in articles:
                enriched = article.copy()
                
                # Identificar temas do artigo
                content = f"{article.get('title', '')} {article.get('summary', '')}".lower()
                themes = []
                
                if any(word in content for word in ['aumento', 'alta', 'crescimento', 'dispara']):
                    themes.append('Aumento de casos')
                if any(word in content for word in ['√≥bito', 'morte', 'mortalidade']):
                    themes.append('Mortalidade')
                if any(word in content for word in ['uti', 'interna√ß√£o', 'hospital']):
                    themes.append('Hospitaliza√ß√£o')
                if any(word in content for word in ['vacina', 'vacina√ß√£o', 'imuniza√ß√£o']):
                    themes.append('Vacina√ß√£o')
                if any(word in content for word in ['alerta', 'preocupa', 'risco']):
                    themes.append('Alerta')
                if any(word in content for word in ['preven√ß√£o', 'cuidados', 'prote√ß√£o']):
                    themes.append('Preven√ß√£o')
                
                enriched['identified_themes'] = themes
                enriched_articles.append(enriched)
            
            analysis = {
                'summary': summary,
                'articles': enriched_articles,
                'context_score': context_score,
                'analysis_timestamp': datetime.now().isoformat(),
                'total_articles_analyzed': len(articles),
                'themes_breakdown': self._get_themes_breakdown(enriched_articles),
                'sources_breakdown': self._get_sources_breakdown(articles)
            }
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            self.log_execution_end(
                execution_id, 
                True, 
                execution_time,
                f"An√°lise de contexto conclu√≠da - Score: {context_score:.1f}/10"
            )
            
            return analysis
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            
            self.log_execution_end(
                execution_id, 
                False, 
                execution_time,
                error=str(e)
            )
            
            logger.error(f"Erro na an√°lise de contexto: {e}", exc_info=True)
            return {
                'summary': 'Erro na an√°lise de contexto das not√≠cias',
                'articles': articles,
                'context_score': 0.0,
                'error': str(e)
            }
    
    def _get_themes_breakdown(self, articles: List[Dict[str, Any]]) -> Dict[str, int]:
        """Retorna contagem de temas identificados."""
        themes_count = {}
        for article in articles:
            for theme in article.get('identified_themes', []):
                themes_count[theme] = themes_count.get(theme, 0) + 1
        return themes_count
    
    def _get_sources_breakdown(self, articles: List[Dict[str, Any]]) -> Dict[str, int]:
        """Retorna contagem por fonte."""
        sources_count = {}
        for article in articles:
            source = article.get('source', 'Desconhecido')
            # Simplificar nome da fonte
            if 'g1.globo.com' in source:
                source = 'G1'
            elif 'folha' in source.lower():
                source = 'Folha de S.Paulo'
            elif 'estadao' in source.lower():
                source = 'Estad√£o'
            elif 'fiocruz' in source.lower():
                source = 'Fiocruz'
            elif 'news api' in source.lower():
                source = 'News API'
            
            sources_count[source] = sources_count.get(source, 0) + 1
        return sources_count
    
    def health_check(self) -> Dict[str, Any]:
        """Verifica sa√∫de da ferramenta de not√≠cias."""
        try:
            status = {
                'status': 'healthy',
                'timestamp': datetime.now().isoformat(),
                'rss_feeds_count': len(self.rss_feeds),
                'news_api_configured': bool(self.news_api_key),
                'cache_entries': len(self.news_cache)
            }
            
            # Testar conectividade com um RSS feed
            try:
                test_feed = feedparser.parse(self.rss_feeds[0])
                status['rss_connectivity'] = 'ok' if test_feed.entries else 'no_entries'
            except Exception as e:
                status['rss_connectivity'] = f'error: {str(e)}'
                status['status'] = 'degraded'
            
            return status
            
        except Exception as e:
            return {
                'status': 'error',
                'timestamp': datetime.now().isoformat(),
                'error': str(e)
            }